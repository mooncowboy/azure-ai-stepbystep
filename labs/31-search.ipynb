{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.3 - Azure AI Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Upload data into Azure Blob Storage\n",
    "\n",
    "1. If you don't have one, create a new Azure Storage account\n",
    "2. Inside that account, create a new container called `healthplans`\n",
    "3. Inside that account, create a new container called `images`\n",
    "   \n",
    "![Storage Account](../img/search02.png)\n",
    "\n",
    "4. Upload the contents of the `data/health-plan` folder into the `healthplans` container\n",
    "5. Upload the contents of the `data/images` folder into the `images` container (you'll use this later)\n",
    "\n",
    "## Step 2: Create a new Azure Search service\n",
    "\n",
    "1. In the Azure Portal, create a new Azure AI Search service.\n",
    "2. Choose France Central (or the region you used before)\n",
    "3. Choose Basic or higher tier\n",
    "4. You can leave everything else as default\n",
    "5. Click on Review + Create\n",
    "\n",
    "![AI Search service](../img/search01.png)\n",
    "\n",
    "## Step 3: Import health plan data into Azure AI Search\n",
    "\n",
    "1. In Azure AI Search, start the \"Import and vectorize data\" wizard\n",
    "\n",
    "![Import and Vectorize](../img/search03.png)\n",
    "\n",
    "2. Select the Azure Blob Storage account and the hotels container\n",
    "3. Check `Enable deletion tracking` and click on Next\n",
    "4. Choose the Azure OpenAI Service created before\n",
    "5. Choose an embedding model which will be used to vectorize the data. If you don't have one yet, just go with `text-embedding-ada-002`\n",
    "6. Click Next\n",
    "7. Leave `Vectorize images` and `Extract text from images` unchecked and click Next\n",
    "8. Leave `Enable semantic ranker` checked and click Next\n",
    "9. Give it a friendly name in `Objects name prefix` (eg: healthplans) and click Create\n",
    "\n",
    "## Step 4: Experiment with queries\n",
    "\n",
    "1. Make sure the indexing job is complete (it may take a few minutes).\n",
    "2. Type `contoso` and see the results\n",
    "\n",
    "![Index](../img/search04.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# Load the environment variables with dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "index_name = \"healthplans\" # replace this if you named your index differently\n",
    "\n",
    "# Create a client\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "\n",
    "print('Using endpoint', service_endpoint)\n",
    "print('Using index', index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the word aerobics is NOT in the documents\n",
    "query = \"pilates\"\n",
    "\n",
    "# Let's start with a simple keyword search\n",
    "results = search_client.search(\n",
    "    search_text=query\n",
    "    )\n",
    "\n",
    "for r in results:\n",
    "    print(r[\"chunk\"])\n",
    "\n",
    "# As you can see, this doesn't produce any results, as we just did a keyword search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's step into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The deployment name of the embedding model used in Azure AI Search\n",
    "embedding_deployment_name = \"ada-embedding\" # Change this if you used another one\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import json \n",
    "\n",
    "# Endpoint and API key can be found in Azure AI Studio -> Project Settings -> Project Properties -> Get API endpoints\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# The name of the deployment to tbe used. Found in Azure AI Studio -> Deployments\n",
    "AZURE_OPENAI_DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_ID\")\n",
    "\n",
    "# Print the endpoint to verify it was loaded correctly\n",
    "print('If you see some text below, the endpoint was loaded successfully.')\n",
    "print(AZURE_OPENAI_ENDPOINT)\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_deployment=embedding_deployment_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector size\n",
    "\n",
    "Vector size is determined by the embedding model. Different models will have different vector sizes. The vector size is important because it determines the number of dimensions in which the data is represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see vectors in action\n",
    "\n",
    "response = client.embeddings.create(input=[query], model=embedding_deployment_name)\n",
    "embeddings = response.data[0].embedding\n",
    "\n",
    "print(\"Vector length is \", len(embeddings))\n",
    "print(\"Vector is \", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do an actual search using just vectors\n",
    "vector_query = VectorizedQuery(vector=embeddings, k_nearest_neighbors=3, fields=\"text_vector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    vector_queries=[vector_query],\n",
    "    top=5\n",
    "    )\n",
    "\n",
    "# this will contain the chunks of the text that were used to generate the vectors\n",
    "chunks = []\n",
    "# store chunks and view results\n",
    "for result in results:\n",
    "    chunks.append(result[\"chunk\"])\n",
    "    #print(json.dumps(result, indent=2))\n",
    "\n",
    "# Check our chunk length. They should be very similar\n",
    "print('Found chunks:', len(chunks))\n",
    "for chunk in chunks:\n",
    "    print(f'Chunk: {chunk}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we get results with vectors?\n",
    "\n",
    "Even if `aerobics` is not in the text, the vector representation of the word is close to the vector representation of `gym` and `fitness`, which are in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do the same query but make it hybrid by passing both vectors and query text \n",
    "vector_query = VectorizedQuery(vector=embeddings, k_nearest_neighbors=3, fields=\"text_vector\")\n",
    "\n",
    "# To do a hybrid search, just add the search_text parameter alongside vector_queries\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    top=5\n",
    "    )\n",
    "\n",
    "# this will contain the chunks of the text that were used to generate the vectors\n",
    "chunks = []\n",
    "# store chunks and view results\n",
    "for result in results:\n",
    "    chunks.append(result[\"chunk\"])\n",
    "    #print(json.dumps(result, indent=2))\n",
    "\n",
    "# Check our chunk length. They should be very similar\n",
    "print('Found chunks:', len(chunks))\n",
    "for chunk in chunks:\n",
    "    print(f'Chunk: {chunk}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting meaningful answers with the help of GPT\n",
    "\n",
    "Notice that pilates is not defined in the document, but yoga and wellness is. \n",
    "Using vectors, were we able to get a meaningful answer for the query related to pilates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now use our GPT deployment to give us meaningful answers\n",
    "\n",
    "# Create a new client for the GPT model\n",
    "gpt_client = AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "# Create a prompt passing the search results\n",
    "\n",
    "completion = gpt_client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_DEPLOYMENT_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that helps users find information about health plans and other HR info. Return the minimum information necessary to answer the user's question.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Am I covered for {query} classes in any of the plans? \\n\\n {chunks}\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab results\n",
    "\n",
    "This was a 10.000 ft view of Azure AI Search, which is a very powerful end-to-end tool for intelligent search. Our main goal was for you to understand the importance of vectors and embeddings in AI applications.\n",
    "\n",
    "In a real world scenario, you could use things like filters to narrrow down the search results even more, among many other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although not relevant for this exapmle, it's a good practice to use semantic reranker to improve the search results\n",
    "# Let's do the same process but enabling semantic reranking\n",
    "\n",
    "# For that, we'll add 4 new parameters to the call\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    top=3,\n",
    "    query_type=\"semantic\",\n",
    "    semantic_configuration_name=\"healthplans-semantic-configuration\",\n",
    "    query_caption=\"extractive\"\n",
    "    )\n",
    "\n",
    "chunks = []\n",
    "# store chunks and view results\n",
    "for result in results:\n",
    "    chunks.append(result[\"chunk\"])\n",
    "\n",
    "# Now let's call our LLM and see the output\n",
    "completion = gpt_client.chat.completions.create(\n",
    "    model=AZURE_OPENAI_DEPLOYMENT_ID,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that helps users find information about health plans and other HR info. Return the minimum information necessary to answer the user's question.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Am I covered for {query} classes? \\n\\n {chunks}\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional next steps\n",
    "\n",
    "There are many labs and end-to-end examples available in the Azure AI Search documentation and in GitHub. Here's some you could try:\n",
    "\n",
    "* https://github.com/Azure/azure-search-vector-samples/tree/main\n",
    "* https://github.com/Azure/azure-search-vector-samples/blob/main/demo-python/code/basic-vector-workflow/azure-search-vector-python-sample.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
