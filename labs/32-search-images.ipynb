{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.4 - Azure AI Search with images\n",
    "\n",
    "Azure AI Search can also store embeddings of images. This is useful for searching for images based on a text prompt or even another image. In this lab, we will use Azure AI Search to index images, store their embeddings and do semantic queries on them.\n",
    "\n",
    "## Step 1 - Upload images\n",
    "\n",
    "1. Go to the Azure Portal and open your storage account\n",
    "2. Navigate to Storage Browser -> Blob Containers and click Add Container\n",
    "3. Call it `images` and click OK\n",
    "4. Open the container and upload the images in the `data/images` folder of this repo\n",
    "\n",
    "![Storage](../img/si01.png)\n",
    "\n",
    "## Step 2 - Create an Azure AI Services account\n",
    "\n",
    "Because we'll be using a feature of Azure AI Vision to get image embeddings, we need to create an Azure AI Services account. This is a multi-service account that shares the same key for its services.\n",
    "\n",
    "1. In the Azure Portal, click on Create a resource\n",
    "2. Search for `Azure AI Services` and click Create\n",
    "3. Choose the resource group and region (use the same as the AI Search service)\n",
    "4. Choose Standard S0 as the pricing tier\n",
    "5. For demo purposes, skip the rest of the wizard and click Review + Create\n",
    "6. Click Create\n",
    "\n",
    "![Storage](../img/si05.png)\n",
    "\n",
    "## Step 3 - Index images in Azure AI Search\n",
    "\n",
    "1. Go to the Azure Portal and open your Azure AI Search service\n",
    "2. Click on Import and Vectorize Data\n",
    "3. Choose the storage account and the `images` container, leave everything else blank on this page\n",
    "4. For text vectorization, choose `Kind: OpenAI`, select your Azure OpenAI Service and an embeddings model\n",
    "\n",
    "![Storage](../img/si02.png)\n",
    "\n",
    "5. Click the `Vectorize images` checkbox\n",
    "6. Choose `Kind: AI Vision vectorization`\n",
    "7. Select your Azure Cognitive Services multi-service account\n",
    "\n",
    "![Storage](../img/si03.png)\n",
    "\n",
    "8. Leave Semantic Ranker enabled\n",
    "9. Click Next \n",
    "10. Use `images` as the object name prefix (this will be the index name) and click Create\n",
    "\n",
    "## Step 4 - See indexed data\n",
    "\n",
    "1. Wait for a few seconds for data to be indexed \n",
    "2. Navigate to Indexes and choose the `images` index\n",
    "3. Enter `*` in the search box and click Search\n",
    "4. Notice how we now have an image_vector that contains the embeddings of the images\n",
    "\n",
    "![Storage](../img/si04.png)\n",
    "\n",
    "## Step 5 - Store Azure Storage account name and key\n",
    "\n",
    "In your `.env` file add the info for the 2 keys:\n",
    "\n",
    "* `AZURE_STORAGE_ACCOUNT_NAME` - the name of your storage account\n",
    "* `AZURE_STORAGE_ACCOUNT_KEY` - the access key of your storage account\n",
    "\n",
    "**NOTE:** After adding these entries, click on the `Restart` button in this jupyter notebook to reload the environment variables.\n",
    "\n",
    "![Storage](../img/si06.png)\n",
    "\n",
    "## Step 5 - Let's do some queries in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizedQuery, VectorizableTextQuery, VectorizableImageBinaryQuery\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Load the environment variables with dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Azure AI Search info\n",
    "service_endpoint = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "key = os.getenv(\"AZURE_AI_SEARCH_API_KEY\")\n",
    "index_name = \"images\" # replace this if you named your index differently\n",
    "\n",
    "# Create a client\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "\n",
    "print('Using endpoint', service_endpoint)\n",
    "print('Using index', index_name)\n",
    "\n",
    "# Connect to storage account where images are stored\n",
    "AZURE_STORAGE_ACCOUNT_NAME = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "AZURE_STORAGE_ACCOUNT_KEY = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "\n",
    "# Create a blob service client\n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://{AZURE_STORAGE_ACCOUNT_NAME}.blob.core.windows.net\", credential=AZURE_STORAGE_ACCOUNT_KEY)\n",
    "\n",
    "print('Using storage account', AZURE_STORAGE_ACCOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to show images\n",
    "def show_image(blob_name):\n",
    "    blob_client = blob_service_client.get_blob_client(\"images\", blob_name)\n",
    "    stream = blob_client.download_blob().readall()\n",
    "    display(Image(stream, width=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to search\n",
    "# Notice:\n",
    "#   - We are using the image_vector field to search\n",
    "#   - We are using the selecting up to 5 results in k_nearest_neighbors\n",
    "def search(query):\n",
    "    r = search_client.search(\n",
    "        vector_queries=[VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"image_vector\")]\n",
    "    )\n",
    "    for doc in r:\n",
    "        # Because this is a vector search, there will always be results so we define a mininum score to only show relevant results\n",
    "        score_threshold = 0.6\n",
    "        if doc[\"@search.score\"] < score_threshold:\n",
    "            break\n",
    "        print(doc[\"@search.score\"],doc[\"title\"])\n",
    "        show_image(doc[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"do you have any backpacks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By asking specifically for red, we should get zero results\n",
    "search(\"do you have any red backpacks?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"I want to go to the mountains. What can you show me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"do you have something for animal lovers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"I'd love to go fishing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search(\"What abot music?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
