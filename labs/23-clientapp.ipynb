{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2.3 - Connect a client app (python)\n",
    "\n",
    "In this lab we'll be connecting from a client app (a jupyter notebook in our case) to the resources we created in Azure AI Studio.\n",
    "\n",
    "For reference, the official docs are [here](https://learn.microsoft.com/en-us/azure/ai-services/openai/use-your-data-quickstart?tabs=bash%2Cpython-new&pivots=programming-language-python).\n",
    "\n",
    "## Ensure required software is installed\n",
    "\n",
    "These should have been installed already as they are in requirements.txt:\n",
    "\n",
    "* `openai` - the OpenAI python library\n",
    "* `python-dotenv` - to load environment variables from a .env file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the environment variables\n",
    "\n",
    "Fill in the values in the `.env` file with the values from the Azure AI Studio resources you created. Specifically:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT\n",
    "AZURE_OPENAI_API_KEY\n",
    "AZURE_OPENAI_DEPLOYMENT_ID\n",
    "```\n",
    "\n",
    "**Restart this notebook** for the changes to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables with dotenv\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "# Endpoint and API key can be found in Azure AI Studio -> Project Settings -> Project Properties -> Get API endpoints\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# The name of the deployment to tbe used. Found in Azure AI Studio -> Deployments\n",
    "AZURE_OPENAI_DEPLOYMENT_ID = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_ID\")\n",
    "\n",
    "# Print the endpoint to verify it was loaded correctly\n",
    "print('If you see some text below, the endpoint was loaded successfully.')\n",
    "print(AZURE_OPENAI_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Create the client \n",
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For convenience, use deployment as var instead of env var name\n",
    "deployment = AZURE_OPENAI_DEPLOYMENT_ID\n",
    "\n",
    "# Make a test call\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the meaning of life?\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get the response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also check the full response\n",
    "print(completion.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a custom system message\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that always begins with 'Hey ya!' and returns responses aproximately 10 words in size\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the meaning of life?\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also tweak the OpenAI parameters\n",
    "# For example, we can increase the temperature to get more creative responses\n",
    "\n",
    "# Notice that the initial value of 50 tokens is not enough to get a full LinkedIn Post\n",
    "# We can increase it to 1000 to get a longer response\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in networking and a world renowed guru on the topic.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a LinkedIn post about the importance of networking.\",\n",
    "        },\n",
    "    ],\n",
    "    temperature=0.5,\n",
    "    max_tokens=10,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the system message to customize the type of output you want\n",
    "# In this case, we'll be asking for json output\n",
    "completion = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in product naming. Your output is always json\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Generate 10 product names for a mountain bike company.\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
